To compile FastTree, do:
gcc -Wall -O3 -finline-functions -funroll-loops -o FastTree -lm FastTree.c
Use -DNO_SSE to turn off use of SSE3 instructions
 (should not be necessary because compiler should not set __SSE__ if
 not available, and modern mallocs should return 16-byte-aligned values)
Use -DOPENMP -fopenmp to use multiple threads (note, old versions of gcc
  may not support -fopenmp)
Use -DTRACK_MEMORY if you want detailed reports of memory usage,
but results are not correct above 4GB because mallinfo stores int values.
It also makes FastTree run significantly slower.

To get usage guidance, do:
FastTree -help

FastTree uses profiles instead of a distance matrix, and computes
support values for each split from the profiles of the 4 nodes
around the split. It stores a profile for each node and a average
profile over all active nodes (the "out-profile" for computing the
total sum of distance to other nodes).  The neighbor joining phase
requires O(N*L*a) space, where N is the number of sequences, L is
the alignment width, and a is the alphabet size. The top-hits
heuristic requires an additional O(N sqrt(N)) memory. After
neighbor-joining, FastTree improves the topology with
nearest-neighbor interchanges (NNIs) and subtree-prune-regraft
moves (SPRs), which does not have a significant additional memory
requirement. (We need only store "up-profiles" on the path from our
current traversal point to the root.) These take O(NLa) time per
round, and with default settings, O(N log(N) L a) time total.
FastTree further improves the topology with maximum-likelihood
NNIs, using similar data structures and complexity, but with a
higher constant factor, and now the "profiles" are actually
posterior distributions for that subtree.  Finally, FastTree
resamples the site likelihoods around each NNI and uses
the Shimodaira Hasegawa test to estimate the reliability of each split.

Overview of the neighbor-joining phase:

Although FastTree uses a log correction on profile distances to
account for multiple substitutions when doing NNIs and SPRs, the
operations on the profiles themselves involve "additive" distances
-- either %different (for nucleotide) or by using an amino acid
similarity matrix (for proteins).  If we are using %different as
our distance matrix then

Profile_distance(A,B) = 1 - sum over characters of freq(A)*freq(B)

and we can average this value over positions. Positions with gaps
are weighted by %ungapped(A) * %ungapped(B).

If we are using an amino acid dissimilarity matrix D(i,j) then at
each position

Profile_distance(A,B) = sum(i,j) freq(A==i) * freq(B==j) * D(i,j)
= sum(k) Ak * Bk * Lambda(k)

where k iterates over 20 eigenvectors, Lambda(k) is the eigenvalue,
and if A==i, then Ak is the kth column of the inverse of the
eigenvector matrix.

The exhaustive approach (-slow) takes O(N**3*L*a) time, but
this can be reduced to as little as O(N**(3/2)*log(N)*L*a) time
by using heuristics.

It uses a combination of three heuristics: a visible set similar to
that of FastTree (Elias & Lagergren 2005), a local hill-climbing
search for a better join (as in relaxed neighbor-joining, Evans et
al. 2006), and a top-hit list to reduce the search space (see
below).

The "visible" set stores, for each node, the best join for that
node, as identified at some point in the past

If top-hits are not being used, then the neighbor-joining phase can
be summarized as:

Compute the out-profile by averaging the leaves
Compute the out-distance of each leaf quickly, using the out-profile
Compute the visible set (or approximate it using top-hits, see below)
Until we're down to 3 active nodes:
  Find the best join in the visible set
 (This involves recomputing the neighbor-joining criterion,
     as out-distances and #active nodes may have changed)
  Follow a chain of best hits (again recomputing the criterion)
 	until we find a locally best join, as in relaxed neighbor joining
  Create a profile of the parent node, either using simple averages (default)
 or using weighted joining as in BIONJ (if -bionj was specified)
  Update the out-profile and the out-distances
  Update the visible set:
     find the best join for the new joined node
     replace hits to the joined children with hits to the parent
     if we stumble across a join for the new node that is better
         than the corresponding entry in the visible set, "reset"
         that entry.

For each iteration, this method does
O(N) work to find the best hit in the visible set
O(L*N*a*log(N)) work to do the local search, where log(N)
 is a pessimistic estimate of the number of iterations. In
     practice, we average <1 iteration for 2,000 sequences.
     With -fastest, this step is omitted.
O(N*a) work to compute the joined profile and update the out-profile
O(L*N*a) work to update the out-distances
O(L*N*a) work to compare the joined profile to the other nodes
     (to find the new entry in the visible set)

and there are N-3 iterations, so it takes O(N**2 * L * log(N) * a) time.

The profile distances give exactly the same result as matrix
distances in neighbor-joining or BIONJ would if there are no gaps
in the alignment. If there are gaps, then it is an
approximation. To get the same result we also store a "diameter"
for each node (diameter is 0 for leaves).

In the simpler case (NJ rather than BIONJ), when we join A and B to
give a new node AB,

Profile(AB) = (A+B)/2
Profile_distance(AB,C) = (Profile_distance(A,C)+Profile_distance(B,C))/2
because the formulas above are linear

And according to the neighor-joining rule,
d(AB,C) = (d(A,C)+d(B,C)-d(A,B))/2

and we can achieve the same value by writing
diameter(AB) = pd(A,B)/2
diameter(leaf) = 0
d(A,B) = pd(A,B) - diameter(A) - diameter(B)

because
d(AB,C) = (d(A,C)+d(B,C)-d(A,B))/2
= (pd(A,C)-diam(A)-diam(C)+pd(B,C)-diam(B)-diam(C)-d(A,B)+diam(A)+diam(B))/2
= (pd(A,C)+pd(B,C))/2 - diam(C) - pd(A,B)
= pd(AB,C) - diam(AB) - diam(C)

If we are using BIONJ, with weight lambda for the join:
Profile(AB) = lambda*A + (1-lambda)*B
then a similar argument gives
diam(AB) = lambda*diam(A) + (1-lambda)*diam(B) + lambda*d(A,AB) + (1-lambda)*d(B,AB),

where, as in neighbor joining,
d(A,AB) = d(A,B) + (total out_distance(A) - total out_distance(B))/(n-2)

A similar recursion formula works for the "variance" matrix of BIONJ,
var(AB,C) = lambda*var(A,C) + (1-lambda)*var(B,C) - lambda*(1-lambda)*var(A,B)
is equivalent to
var(A,B) = pv(A,B) - vd(A) - vd(B), where
pv(A,B) = pd(A,B)
vd(A) = 0 for leaves
vd(AB) = lambda*vd(A) + (1-lambda)*vd(B) + lambda*(1-lambda)*var(A,B)

The top-hist heuristic to reduce the work below O(N**2*L) stores a top-hit
list of size m=sqrt(N) for each active node.

The list can be initialized for all the leaves in sub (N**2 * L) time as follows:
Pick a "seed" sequence and compare it to all others
Store the top m hits of the seed as its top-hit list
Take "close" hits of the seed(within the top m, and see the "close" parameter),
   and assume that their top m hits lie within the top 2*m hits of the seed.
   So, compare them to the seed's neighors (if they do not already
   have a top hit list) and set their top hits.

This method does O(N*L) work for each seed, or O(N**(3/2)*L) work total.

To avoid doing O(N*L) work at each iteration, we need to avoid
updating the visible set and the out-distances. So, we use "stale"
out-distances, and when searching the visible set for the best hit,
we only inspect the top m=sqrt(N) entries. We then update those
out-distances (up to 2*m*L*a work) and then find the best hit.

To avoid searching the entire visible set, FastTree keeps
and updates a list of the top sqrt(N) entries in the visible set.
This costs O(sqrt(N)) time per join to find the best entry and to
update, or (N sqrt(N)) time overall.

Similarly, when doing the local hill-climbing, we avoid O(N*L) work
by only considering the top-hits for the current node. So this adds
O(m*a*log(N)) work per iteration.

When we join two nodes, we compute profiles and update the
out-profile as before. We need to compute the best hits of the node
-- we merge the lists for the children and select the best up-to-m
hits. If the top hit list contains a stale node we replace it with
its parent. If we still have <m/2 entries, we do a "refresh".

In a "refresh", similar to the fast top-hit computation above, we
compare the "seed", in this case the new joined node, to all other
nodes. We compare its close neighbors (the top m hits) to all
neighbors (the top 2*m hits) and update the top-hit lists of all
neighbors (by merging to give a list of 3*m entries and then
selecting the best m entries).

Finally, during these processes we update the visible sets for
other nodes with better hits if we find them, and we set the
visible entry for the new joined node to the best entry in its
top-hit list. (And whenever we update a visible entry, we
do O(sqrt(N)) work to update the top-visible list.)
These udpates are not common so they do not alter the
O(N sqrt(N) log(N) L a) total running time for the joining phase.

Second-level top hits

With -fastest or with -2nd, FastTree uses an additional "2nd-level" top hits
heuristic to reduce the running time for the top-hits phase to
O(N**1.25 L) and for the neighbor-joining phase to O(N**1.25 L a).
This also reduces the memory usage for the top-hits lists to
O(N**1.25), which is important for alignments with a million
sequences. The key idea is to store just q = sqrt(m) top hits for
most sequences.

Given the neighbors of A -- either for a seed or for a neighbor
from the top-hits heuristic, if B is within the top q hits of A, we
set top-hits(B) from the top 3*q top-hits of A. And, we record that
A is the "source" of the hits for B, so if we run low on hits for
B, instead of doing a full refresh, we can do top-hits(B) :=
top-hits(B) union top-hits(active_ancestor(A)).
During a refresh, these "2nd-level" top hits are updated just as
normal, but the source is maintained and only q entries are stored,
until we near the end of the neighbor joining phase (until the
root as 2*m children or less).

Parallel execution with OpenMP

If you compile FastTree with OpenMP support, it will take
advantage of multiple CPUs on one machine. It will parallelize:

The top hits phase
Comparing one node to many others during the NJ phase (the simplest kind of join)
The refresh phase
Optimizing likelihoods for 3 alternate topologies during ML NNIs and ML supports
(only 3 threads can be used)

This accounts for most of the O(N L a) or slower steps except for
minimum-evolution NNIs (which are fast anyway), minimum-evolution SPRs,
selecting per-site rates, and optimizing branch lengths outside of ML NNIs.

Parallelizing the top hits phase may lead to a slight change in the tree,
as some top hits are computed from different (and potentially less optimal source).
This means that results on repeated runs may not be 100% identical.
However, this should not have any significant effect on tree quality
after the NNIs and SPRs.

The OpenMP code also turns off the star-topology test during ML
NNIs, which may lead to slight improvements in likelihood.
